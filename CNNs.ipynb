{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUuusoYphxEr"
   },
   "source": [
    "# Genre song classification\n",
    "In out database we have spectrograms and chomagrams from different song genres: Alternative, Classical, Dance, Pop, Rock and Techno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgU0YiU3hxEs"
   },
   "source": [
    "### Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tdXfnesZhxEt",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (0.13.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from seaborn) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Import general purpose python libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image # For handling the images\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# Import different Keras functionalities\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Add, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import concatenate\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import image_dataset_from_directory\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Import function to plot the results\n",
    "!pip install seaborn\n",
    "import plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acQvmDp6hxEt"
   },
   "source": [
    "### Data Configuration Parameters\n",
    "Configuration variables related to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qO5OSJcghxEu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classess to classify are: ['Alternative', 'Classical', 'Dance', 'Pop', 'Rock', 'Techno']\n"
     ]
    }
   ],
   "source": [
    "# Randomize the initial network weights\n",
    "random_seed = True\n",
    "\n",
    "# Paths to where training, testing, and validation images are\n",
    "database_dir = 'dataset/'\n",
    "train_dir = 'dataset/training/spectrogram'\n",
    "val_dir = 'dataset/val/spectrogram'\n",
    "test_dir = 'dataset/test/spectrogram'\n",
    "\n",
    "# Directory where to store weights of the model and results\n",
    "root_dir = \"results\"\n",
    "# Create root directory for results if it does not exist\n",
    "if not os.path.exists(root_dir):\n",
    "    os.makedirs(root_dir)\n",
    "\n",
    "# Output dimension (number of sublects in our problem)\n",
    "num_classes = 6\n",
    "\n",
    "# Name of each gesture of the database\n",
    "CLASSES = [x for x in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, x))]\n",
    "print(f'The classess to classify are: {CLASSES}')\n",
    "\n",
    "# Parameters that characterize the images\n",
    "img_height = 480\n",
    "img_width = 640\n",
    "img_channels = 3 # although some images could be rgb, we work with grayscale images\n",
    "color_mode = 'rgb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlekhinYlXrA"
   },
   "source": [
    "## Configuration Training Parameters & Loading of training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1jCmerTZldzN",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1186 files belonging to 6 classes.\n",
      "Found 204 files belonging to 6 classes.\n",
      "Found 204 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Parameters that configures the training process\n",
    "batch_size = 1  # Batch size\n",
    "epochs = 30  # Number of epochs\n",
    "initial_lr = 1e-4   # Learning rate\n",
    "seed = 42  # Random number\n",
    "num_layers = 'all'\n",
    "modelCNN = 'ResNet'  # VGG, ResNet, Random_Model\n",
    "version = f'BS{batch_size}_E{epochs}_LR{initial_lr}_Layers{num_layers}'\n",
    "experiment_dir = f'{root_dir}/{modelCNN}'\n",
    "\n",
    "# Create experiment directory if it does not exist\n",
    "if not os.path.exists(experiment_dir):\n",
    "    os.makedirs(experiment_dir)\n",
    "\n",
    "# 1. Generate train dataset (ds) from directory of samples\n",
    "train_ds = image_dataset_from_directory(directory=train_dir,\n",
    "                                        label_mode = 'categorical',\n",
    "                                        class_names=CLASSES,\n",
    "                                        batch_size=batch_size,\n",
    "                                        color_mode=color_mode,\n",
    "                                        image_size=(img_width,img_height), shuffle=True)\n",
    "\n",
    "# 2. Generate validation dataset (ds) from directory of samples\n",
    "val_ds  = image_dataset_from_directory(directory=val_dir,\n",
    "                                       label_mode = 'categorical',\n",
    "                                       class_names=CLASSES,\n",
    "                                       batch_size=batch_size,\n",
    "                                       color_mode=color_mode,\n",
    "                                       image_size=(img_width,img_height))\n",
    "\n",
    "# 3. Generate test dataset (ds) from directory of samples\n",
    "test_ds = image_dataset_from_directory(directory=test_dir,\n",
    "                                       label_mode = 'categorical',\n",
    "                                       class_names=CLASSES,\n",
    "                                       batch_size=batch_size,\n",
    "                                       color_mode=color_mode,\n",
    "                                       image_size=(img_width,img_height),\n",
    "                                       shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yx6J0q-tm0CO"
   },
   "source": [
    "## Function def for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vxujQd_hxEu"
   },
   "source": [
    "# Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_AbmfZWhxEv"
   },
   "source": [
    "## Available Models: VGG-16 & ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSyy37I-gRn5"
   },
   "source": [
    "### VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LV2RuydXhxEv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def VGG16(img_width,img_height,img_channels):\n",
    "\t#  dropout rate for FC layers\n",
    "\tdropout=0.5\n",
    "\n",
    "\t# CNN architecture\n",
    "\tinput_image = Input(shape=(img_width,img_height,img_channels))\n",
    "\tx1 = Conv2D(64, (3, 3),padding='same', activation='relu')(input_image)\n",
    "\tx1 = Conv2D(64, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = MaxPooling2D((2, 2))(x1)\n",
    "\tx1 = Conv2D(128, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = Conv2D(128, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = MaxPooling2D((2, 2))(x1)\n",
    "\tx1 = Conv2D(256, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = Conv2D(256, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = Conv2D(256, (1, 1),padding='same', activation='relu')(x1)\n",
    "\tx1 = MaxPooling2D((2, 2))(x1)\n",
    "\tx1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = Conv2D(512, (1, 1),padding='same', activation='relu')(x1)\n",
    "\tx1 = MaxPooling2D((2, 2))(x1)\n",
    "\tx1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = Conv2D(512, (3, 3),padding='same', activation='relu')(x1)\n",
    "\tx1 = Conv2D(512, (1, 1),padding='same', activation='relu')(x1)\n",
    "\tx1 = MaxPooling2D((2, 2))(x1)\n",
    "\n",
    "\tx1 = Flatten()(x1)\n",
    "\n",
    "\tx=Dense(4096, activation='relu', kernel_constraint=MaxNorm(3))(x1)\n",
    "\tx=Dropout(dropout)(x)\n",
    "\tx=Dense(4096, activation='relu', kernel_constraint=MaxNorm(3))(x)\n",
    "\tx=Dropout(dropout)(x)\n",
    "\tout= Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "\tmodel = Model(inputs = input_image, outputs = out)\n",
    "\n",
    "\treturn model\n",
    "\n",
    "model = VGG16(img_width,img_height,img_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e1g3e3ego7r"
   },
   "source": [
    "### RestNet\n",
    "This ResNet network it has been coded and not obtained from an already existing project. This ResNet structure has been chosen because its simplicity and, as seen along the curse, good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "c-63WTaigsY9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RestNet (img_width,img_height,img_channels):\n",
    "  dropout=0.5 # Para evitar que haya overfitting cancela algunas conexiones entre las neuronas aleatoriamente.\n",
    "\n",
    "  # CNN architecture\n",
    "  input_image = Input(shape=(img_width,img_height,img_channels))\n",
    "  x0 = Conv2D(64, (3, 3),padding='same', activation='relu')(input_image)\n",
    "  x1 = Conv2D(64, (3, 3),padding='same', activation='relu')(x0)\n",
    "  x1 = MaxPooling2D((2, 2))(x1)\n",
    "  x2 = Conv2D(128, (3, 3),padding='same', activation='relu')(x1)\n",
    "  x3 = Conv2D(128, (3, 3),padding='same')(x2)\n",
    "  x4 = Add()([x3, x2])\n",
    "  x4 = Activation('relu')(x4)\n",
    "  x4 = MaxPooling2D((2, 2))(x4)\n",
    "  x4 = Conv2D(256, (3, 3),padding='same', activation='relu')(x4)\n",
    "  x5 = Conv2D(256, (3, 3),padding='same', activation='relu')(x4)\n",
    "  x5 = Conv2D(256, (1, 1),padding='same')(x5)\n",
    "  x6 = Add()([x5, x4])\n",
    "  x6 = Activation('relu')(x6)\n",
    "  x6 = MaxPooling2D((2, 2))(x6)\n",
    "  x6 = Conv2D(512, (3, 3),padding='same', activation='relu')(x6)\n",
    "  x7 = Conv2D(512, (3, 3),padding='same', activation='relu')(x6)\n",
    "  x7 = Conv2D(512, (1, 1),padding='same')(x7)\n",
    "  x8 = Add()([x7, x6])\n",
    "  x8 = Activation('relu')(x8)\n",
    "  x8 = MaxPooling2D((2, 2))(x8)\n",
    "  x8 = Conv2D(512, (3, 3),padding='same', activation='relu')(x8)\n",
    "  x9 = Conv2D(512, (3, 3),padding='same', activation='relu')(x8)\n",
    "  x9 = Conv2D(512, (1, 1),padding='same')(x9)\n",
    "  x10 = Add()([x9, x8])\n",
    "  x10 = Activation('relu')(x10)\n",
    "  x10 = MaxPooling2D((2, 2))(x10)\n",
    "  x10 = Flatten()(x10)\n",
    "\n",
    "  x=Dense(4096, activation='relu', kernel_constraint=MaxNorm(3))(x10)\n",
    "  x=Dropout(dropout)(x)\n",
    "  x=Dense(4096, activation='relu', kernel_constraint=MaxNorm(3))(x)\n",
    "  x=Dropout(dropout)(x)\n",
    "  out= Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs = input_image, outputs = out);\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn9iTkKthi13"
   },
   "source": [
    "## Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V9Yx3WzqgnKl",
    "outputId": "a5345b7f-6f99-4996-ae79-9b4329113322",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 640, 480, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 640, 480, 64  1792        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 640, 480, 64  36928       ['conv2d_13[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 320, 240, 64  0          ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 320, 240, 12  73856       ['max_pooling2d_5[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 320, 240, 12  147584      ['conv2d_15[0][0]']              \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 320, 240, 12  0           ['conv2d_16[0][0]',              \n",
      "                                8)                                'conv2d_15[0][0]']              \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 320, 240, 12  0           ['add[0][0]']                    \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 160, 120, 12  0          ['activation[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 160, 120, 25  295168      ['max_pooling2d_6[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 160, 120, 25  590080      ['conv2d_17[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 160, 120, 25  65792       ['conv2d_18[0][0]']              \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 160, 120, 25  0           ['conv2d_19[0][0]',              \n",
      "                                6)                                'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 160, 120, 25  0           ['add_1[0][0]']                  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 80, 60, 256)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 80, 60, 512)  1180160     ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 80, 60, 512)  2359808     ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 80, 60, 512)  262656      ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 80, 60, 512)  0           ['conv2d_22[0][0]',              \n",
      "                                                                  'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 80, 60, 512)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 40, 30, 512)  0          ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 40, 30, 512)  2359808     ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 40, 30, 512)  2359808     ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 40, 30, 512)  262656      ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 40, 30, 512)  0           ['conv2d_25[0][0]',              \n",
      "                                                                  'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 40, 30, 512)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 20, 15, 512)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 153600)       0           ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4096)         629149696   ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 4096)         0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 4096)         16781312    ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 4096)         0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 6)            24582       ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 655,951,686\n",
      "Trainable params: 655,951,686\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "if modelCNN == 'VGG-16':\n",
    "    model = VGG16(img_width,img_height,img_channels)\n",
    "elif modelCNN == 'ResNet':\n",
    "    model = RestNet (img_width,img_height,img_channels)\n",
    "else:\n",
    "    print('Wrong model selection or Model no available\\n')\n",
    "\n",
    "# Print the architecture of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp_FzEzYhxEv"
   },
   "source": [
    "## Set model training process\n",
    "#### Configuration of several training decisions:\n",
    "1. Optimizer using `Adam`\n",
    "2. Model training configuration using `compile` with `categorical_crossentropy` due to the classification labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FAy4roRXhxEw",
    "outputId": "6d1aa3a8-14e9-4523-d714-51cd3c538bf7"
   },
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "if random_seed:\n",
    "    seed = np.random.randint(0,2*31-1)\n",
    "else:\n",
    "    seed = 5\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "\n",
    "# 1. Configure optimizer\n",
    "adam = Adam(learning_rate=initial_lr)\n",
    "\n",
    "# 2. Configure training process\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['categorical_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6qILA4XhxEw"
   },
   "source": [
    "## Train the model\n",
    "1. Load parameters from previous trainings if they exist.\n",
    "2. Fit the model\n",
    "3. Save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqctz0VshxEw",
    "outputId": "e0ef1a1f-9a09-4d4a-84e3-08505298b42e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-18 11:09:00.660249: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-18 11:09:11.421949: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB (rounded to 2516582400)requested by op gradient_tape/model_1/dense_3/MatMul/MatMul_1\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2024-01-18 11:09:11.422259: W tensorflow/tsl/framework/bfc_allocator.cc:497] ********************_______________*********************************************************________\n",
      "2024-01-18 11:09:11.422293: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:730 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[153600,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/model_1/dense_3/MatMul/MatMul_1' defined at (most recent call last):\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1067/1742920266.py\", line 13, in <module>\n      history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 585, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 643, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 519, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_1/dense_3/MatMul/MatMul_1'\nOOM when allocating tensor with shape[153600,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model_1/dense_3/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2837]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m weights_load_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#if weights_load_path:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#    try:\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#        model.load_weights(weights_load_path)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Save weights\u001b[39;00m\n\u001b[1;32m     16\u001b[0m weights_save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(experiment_rootdir, weights_path)\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model_1/dense_3/MatMul/MatMul_1' defined at (most recent call last):\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_1067/1742920266.py\", line 13, in <module>\n      history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 585, in minimize\n      grads_and_vars = self._compute_gradients(\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 643, in _compute_gradients\n      grads_and_vars = self._get_gradients(\n    File \"/opt/conda/envs/sagemaker-distribution/lib/python3.8/site-packages/keras/optimizers/legacy/optimizer_v2.py\", line 519, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/model_1/dense_3/MatMul/MatMul_1'\nOOM when allocating tensor with shape[153600,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model_1/dense_3/MatMul/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_2837]"
     ]
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "weights_path = f\"weights_{version}.h5\" # Name of the file to store the weights\n",
    "weights_file = Path(weights_path)\n",
    "weights_load_path = f'{experiment_dir}/{weights_path}'\n",
    "#if weights_load_path:\n",
    "#    try:\n",
    "#        model.load_weights(weights_load_path)\n",
    "#        print(\"Loaded model from {}\".format(weights_load_path))\n",
    "#    except:\n",
    "#        print(\"Impossible to find weight path. Returning untrained model\")\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Save weights\n",
    "weights_save_path = os.path.join(experiment_rootdir, weights_path)\n",
    "model.save_weights(weights_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qesOAn11hxEw"
   },
   "source": [
    "### Plot history for accuracy and loss for the training  process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "8f60KHH6hxEx",
    "outputId": "76b8a2c1-955d-4c85-c02f-8fe1d4915be1"
   },
   "outputs": [],
   "source": [
    "plots.accloss(history, modelCNN, experiment_dir, version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4krKV8PShxEx"
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "racjpVoMhxEy"
   },
   "source": [
    "### Testing process\n",
    "Compute the loss function and accuracy for the test data (using `evaluate`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T14:59:10.580861Z",
     "start_time": "2024-01-02T14:59:10.347719Z"
    },
    "id": "4u4LEvGDhxEy"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "scores = model.evaluate(test_ds, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Loss: %.2f\" % scores[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8nKRlglhxEy"
   },
   "source": [
    "### Generation of the predictions and the confusion matrix for the test data\n",
    "1.   Compute predictions with `predict`\n",
    "2.   Select the most probable class with `argmax`\n",
    "\n",
    "The confusion matrix will be shown with `plotcm`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "id": "vVDE9mRghxEy",
    "outputId": "b6ab047b-dd88-4c82-844f-fba597731dd8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Get predictions\n",
    "prob_class = model.predict(test_ds, batch_size=batch_size)\n",
    "\n",
    "# 2. Prediced labels\n",
    "y_pred = tf.argmax(prob_class, axis=-1)\n",
    "\n",
    "# Get ground truth\n",
    "y_true = tf.argmax(tf.concat([label for image, label in test_ds], axis=0), axis=1)\n",
    "\n",
    "# Visualize confusion matrix                                           \n",
    "plotcm.plotcm(experiment_rootdir, version, y_true, y_pred, CLASSES, experiment_rootdir, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "EgU0YiU3hxEs",
    "acQvmDp6hxEt",
    "HlekhinYlXrA",
    "Yx6J0q-tm0CO",
    "eSyy37I-gRn5",
    "9e1g3e3ego7r"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "sagemaker-distribution:Python",
   "language": "python",
   "name": "conda-env-sagemaker-distribution-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
